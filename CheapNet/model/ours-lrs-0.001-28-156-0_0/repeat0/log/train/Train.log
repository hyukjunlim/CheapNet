ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-4.2544, train_rmse-2.0626, valid_rmse-2.8339, valid_pr-0.2624
epoch-1, train_loss-3.1598, train_rmse-1.7776, valid_rmse-2.0716, valid_pr-0.4201
epoch-2, train_loss-2.9579, train_rmse-1.7199, valid_rmse-1.8570, valid_pr-0.4077
epoch-3, train_loss-2.8369, train_rmse-1.6843, valid_rmse-1.7986, valid_pr-0.3230
epoch-4, train_loss-2.7149, train_rmse-1.6477, valid_rmse-1.5068, valid_pr-0.5858
valid_rmse-1.5068, valid_pr-0.5858, test2013_rmse-1.6885, test2013_pr-0.7225, test2016_rmse-1.5589, test2016_pr-0.7278, test2019_rmse-1.4567, test2019_pr-0.5817
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-4.5727, train_rmse-2.1384, valid_rmse-2.3810, valid_pr-0.2663
epoch-1, train_loss-2.8947, train_rmse-1.7014, valid_rmse-1.7439, valid_pr-0.4700
epoch-2, train_loss-2.7316, train_rmse-1.6528, valid_rmse-2.3272, valid_pr-0.2932
epoch-3, train_loss-2.5849, train_rmse-1.6078, valid_rmse-1.7626, valid_pr-0.4476
epoch-4, train_loss-2.4438, train_rmse-1.5633, valid_rmse-1.8525, valid_pr-0.4512
valid_rmse-1.7439, valid_pr-0.4700, test2013_rmse-1.9621, test2013_pr-0.5620, test2016_rmse-1.7822, test2016_pr-0.6112, test2019_rmse-1.5833, test2019_pr-0.5420
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-5.3421, train_rmse-2.3113, valid_rmse-1.8247, valid_pr-0.3845
epoch-1, train_loss-2.8280, train_rmse-1.6817, valid_rmse-1.5719, valid_pr-0.5565
epoch-2, train_loss-2.5771, train_rmse-1.6053, valid_rmse-1.8241, valid_pr-0.4258
epoch-3, train_loss-2.4384, train_rmse-1.5615, valid_rmse-1.6865, valid_pr-0.5051
epoch-4, train_loss-2.2898, train_rmse-1.5132, valid_rmse-1.4915, valid_pr-0.6222
valid_rmse-1.4915, valid_pr-0.6222, test2013_rmse-1.6527, test2013_pr-0.7283, test2016_rmse-1.4500, test2016_pr-0.7717, test2019_rmse-1.4465, test2019_pr-0.6140
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-6.7828, train_rmse-2.6044, valid_rmse-1.6567, valid_pr-0.5383
epoch-1, train_loss-2.6988, train_rmse-1.6428, valid_rmse-1.5180, valid_pr-0.5788
epoch-2, train_loss-2.4896, train_rmse-1.5779, valid_rmse-1.5969, valid_pr-0.5454
epoch-3, train_loss-2.3555, train_rmse-1.5348, valid_rmse-1.4702, valid_pr-0.6231
epoch-4, train_loss-2.1829, train_rmse-1.4775, valid_rmse-1.4096, valid_pr-0.6504
valid_rmse-1.4096, valid_pr-0.6504, test2013_rmse-1.4700, test2013_pr-0.8146, test2016_rmse-1.4384, test2016_pr-0.7716, test2019_rmse-1.3762, test2019_pr-0.6396
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-9.8128, train_rmse-3.1325, valid_rmse-1.5869, valid_pr-0.5627
epoch-1, train_loss-2.6255, train_rmse-1.6203, valid_rmse-1.6098, valid_pr-0.4967
epoch-2, train_loss-2.4149, train_rmse-1.5540, valid_rmse-1.4979, valid_pr-0.5849
epoch-3, train_loss-2.2295, train_rmse-1.4932, valid_rmse-1.4459, valid_pr-0.6272
epoch-4, train_loss-2.1394, train_rmse-1.4627, valid_rmse-1.6006, valid_pr-0.6090
valid_rmse-1.4459, valid_pr-0.6272, test2013_rmse-1.5823, test2013_pr-0.7909, test2016_rmse-1.4994, test2016_pr-0.7714, test2019_rmse-1.4286, test2019_pr-0.6009
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-15.9466, train_rmse-3.9933, valid_rmse-1.7866, valid_pr-0.5442
epoch-1, train_loss-2.6472, train_rmse-1.6270, valid_rmse-1.9825, valid_pr-0.3800
epoch-2, train_loss-2.3342, train_rmse-1.5278, valid_rmse-1.4845, valid_pr-0.6235
epoch-3, train_loss-2.2026, train_rmse-1.4841, valid_rmse-1.5013, valid_pr-0.6206
epoch-4, train_loss-2.0098, train_rmse-1.4177, valid_rmse-1.4981, valid_pr-0.6058
valid_rmse-1.4845, valid_pr-0.6235, test2013_rmse-1.6633, test2013_pr-0.7769, test2016_rmse-1.5565, test2016_pr-0.7722, test2019_rmse-1.4430, test2019_pr-0.6052
ours-lrs-0.001-28-156-0, lr=0.001, seed=191
train_CheapNet.py
train data: 11904
valid data: 1000
test2013 data: 107
test2016 data: 285
test2019 data: 4366
GIGN params # : 1331241
epoch-0, train_loss-24.7263, train_rmse-4.9726, valid_rmse-5.5758, valid_pr--0.0176
epoch-1, train_loss-6.1909, train_rmse-2.4882, valid_rmse-1.8876, valid_pr-0.3988
epoch-2, train_loss-2.4815, train_rmse-1.5753, valid_rmse-1.6796, valid_pr-0.5532
epoch-3, train_loss-2.2302, train_rmse-1.4934, valid_rmse-1.4757, valid_pr-0.6258
epoch-4, train_loss-2.0483, train_rmse-1.4312, valid_rmse-1.4453, valid_pr-0.6394
valid_rmse-1.4453, valid_pr-0.6394, test2013_rmse-1.4209, test2013_pr-0.8042, test2016_rmse-1.3916, test2016_pr-0.7741, test2019_rmse-1.4228, test2019_pr-0.6321
